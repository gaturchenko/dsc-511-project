{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import modules, declare constants, export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from bqWrapper.bq import bqWrapper\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bqw = bqWrapper()\n",
    "spark = bqw.connection\n",
    "df_train = bqw.create_bigquery_connection(connection=spark, table='training_data')\n",
    "df_val = bqw.create_bigquery_connection(connection=spark, table='validation_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHORTS_DIMENSIONS = ['first_touch_date', 'traffic_source', 'os', 'country']\n",
    "TARGET_VAR = 'cohort_ltv_avg_lifetime'\n",
    "evaluator = RegressionEvaluator(labelCol=TARGET_VAR, predictionCol='prediction', metricName='rmse')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate train, test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use Min-Max scaling. Since our data is sparse, normalizing values to 0-1 scale will help adjust for this factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max scaled data\n",
    "feature_list = [col for col in df_train.columns if (col not in COHORTS_DIMENSIONS) and (col != TARGET_VAR)]\n",
    "assemblers = [VectorAssembler(inputCols=[col], outputCol=col + \"_vec\") for col in feature_list]\n",
    "scalers = [MinMaxScaler(inputCol=col + \"_vec\", outputCol=col + \"_scaled\") for col in feature_list]\n",
    "pipeline = Pipeline(stages=assemblers + scalers)\n",
    "scalerModel = pipeline.fit(df_train)\n",
    "df_train_trans = scalerModel.transform(df_train)\n",
    "assembler = VectorAssembler(inputCols=feature_list, outputCol='features')\n",
    "df_train_trans = assembler.transform(df_train_trans)\n",
    "(X_train_mm, X_test_mm) = df_train_trans.randomSplit([0.8, 0.2], seed=143)\n",
    "# Validation set\n",
    "df_val_trans = assembler.transform(df_val)\n",
    "df_val_pipe = df_val.drop(*(COHORTS_DIMENSIONS+['features']))\n",
    "# Adjusted for cv\n",
    "X_train_pipe = X_train_mm.drop(*(COHORTS_DIMENSIONS+['features']))\n",
    "X_test_pipe = X_test_mm.drop(*(COHORTS_DIMENSIONS+['features']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy baseline average-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_avg = X_train_mm.select(mean(df_train.cohort_ltv_avg_lifetime)).collect()[0][f'avg({TARGET_VAR})']\n",
    "df_avg = X_test_mm.select(TARGET_VAR)\n",
    "df_avg = df_avg.withColumn('prediction', lit(target_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.992390089910161"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rmse = evaluator.evaluate(df_avg)\n",
    "avg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.015719873031029"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_val = df_val.select(TARGET_VAR)\n",
    "df_avg_val = df_avg_val.withColumn('prediction', lit(target_avg))\n",
    "avg_rmse_val = evaluator.evaluate(df_avg_val)\n",
    "avg_rmse_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters for all types of regression\n",
    "FEATURES_COL = 'features'\n",
    "STANDARDIZATION = False\n",
    "MAXITER = 10000\n",
    "REGPARAM = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LinearRegression(\n",
    "    labelCol=TARGET_VAR,\n",
    "    featuresCol=FEATURES_COL,\n",
    "    elasticNetParam=1,\n",
    "    regParam=REGPARAM,\n",
    "    standardization=STANDARDIZATION,\n",
    "    maxIter=MAXITER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = lasso.fit(X_train_mm)\n",
    "lasso_predictions = lasso_model.transform(X_test_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.374706262242034"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_rmse = evaluator.evaluate(lasso_predictions)\n",
    "lasso_rmse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barely better then baseline. Implement cross-validation to improve results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler, lasso])\n",
    "paramGrid_lasso = ParamGridBuilder() \\\n",
    "    .addGrid(lasso.regParam, [0.1, 0.5, 1, 5, 10]) \\\n",
    "    .build()\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid_lasso,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv_model = crossval.fit(X_train_pipe)\n",
    "lasso_cv_predictions = lasso_cv_model.transform(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.404330442625282"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv_rmse = evaluator.evaluate(lasso_cv_predictions)\n",
    "lasso_cv_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({Param(parent='LinearRegression_4514dbe62b5b', name='regParam', doc='regularization parameter (>= 0).'): 0.1}, 6.884123118104254)\n",
      "({Param(parent='LinearRegression_4514dbe62b5b', name='regParam', doc='regularization parameter (>= 0).'): 0.5}, 6.6098746101420085)\n",
      "({Param(parent='LinearRegression_4514dbe62b5b', name='regParam', doc='regularization parameter (>= 0).'): 1.0}, 6.683507159372043)\n",
      "({Param(parent='LinearRegression_4514dbe62b5b', name='regParam', doc='regularization parameter (>= 0).'): 5.0}, 7.02706676288023)\n",
      "({Param(parent='LinearRegression_4514dbe62b5b', name='regParam', doc='regularization parameter (>= 0).'): 10.0}, 7.336225221398381)\n"
     ]
    }
   ],
   "source": [
    "for i in zip(paramGrid_lasso, lasso_cv_model.avgMetrics):\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation didn't really help much, although its train RMSE was at least quite an improvement. Let us evaluate both models on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.817859626746012"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_predictions_val = lasso_model.transform(df_val_trans)\n",
    "lasso_rmse_val = evaluator.evaluate(lasso_predictions_val)\n",
    "lasso_rmse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8835436293697185"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv_predictions_val = lasso_cv_model.transform(df_val_pipe)\n",
    "lasso_cv_rmse_val = evaluator.evaluate(lasso_cv_predictions_val)\n",
    "lasso_cv_rmse_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Lasso model on default parameters outperformed the CV one on validation set as well</p>\n",
    "<p>Let us test other models before trying to extract some evidence from our predictions</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = LinearRegression(\n",
    "    labelCol=TARGET_VAR,\n",
    "    featuresCol=FEATURES_COL,\n",
    "    elasticNetParam=0,\n",
    "    regParam=REGPARAM,\n",
    "    standardization=STANDARDIZATION,\n",
    "    maxIter=MAXITER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = ridge.fit(X_train_mm)\n",
    "ridge_predictions = ridge_model.transform(X_test_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.493504900099856"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_rmse = evaluator.evaluate(ridge_predictions)\n",
    "ridge_rmse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is worse than the base Lasso model. Let us try to improve it with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler, ridge])\n",
    "paramGrid_ridge = ParamGridBuilder() \\\n",
    "    .addGrid(ridge.regParam, [0.1, 0.5, 1, 5, 10]) \\\n",
    "    .build()\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid_ridge,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_model = crossval.fit(X_train_pipe)\n",
    "ridge_cv_predictions = ridge_cv_model.transform(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.435716567217392"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv_rmse = evaluator.evaluate(ridge_cv_predictions)\n",
    "ridge_cv_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({Param(parent='LinearRegression_4514dbe62b5b', name='regParam', doc='regularization parameter (>= 0).'): 0.1}, 7.041097972345739)\n",
      "({Param(parent='LinearRegression_4514dbe62b5b', name='regParam', doc='regularization parameter (>= 0).'): 0.5}, 6.862878757818502)\n",
      "({Param(parent='LinearRegression_4514dbe62b5b', name='regParam', doc='regularization parameter (>= 0).'): 1.0}, 6.783176302305053)\n",
      "({Param(parent='LinearRegression_4514dbe62b5b', name='regParam', doc='regularization parameter (>= 0).'): 5.0}, 6.670064829309338)\n",
      "({Param(parent='LinearRegression_4514dbe62b5b', name='regParam', doc='regularization parameter (>= 0).'): 10.0}, 6.648940445097065)\n"
     ]
    }
   ],
   "source": [
    "for i in zip(paramGrid_ridge, ridge_cv_model.avgMetrics):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>CV slightly improved the results of base model for Ridge regression, and it is still worse than base</p>\n",
    "\n",
    "<p>However, we can go into second round of CV as we didn't reach the turning point</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler, ridge])\n",
    "paramGrid_ridge = ParamGridBuilder() \\\n",
    "    .addGrid(ridge.regParam, [i for i in range(10, 35, 5)]) \\\n",
    "    .build()\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid_ridge,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_model = crossval.fit(X_train_pipe)\n",
    "ridge_cv_predictions = ridge_cv_model.transform(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.412693361104662"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv_rmse = evaluator.evaluate(ridge_cv_predictions)\n",
    "ridge_cv_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({Param(parent='LinearRegression_379bee5804b7', name='regParam', doc='regularization parameter (>= 0).'): 10.0}, 6.648940445097065)\n",
      "({Param(parent='LinearRegression_379bee5804b7', name='regParam', doc='regularization parameter (>= 0).'): 15.0}, 6.639043413764755)\n",
      "({Param(parent='LinearRegression_379bee5804b7', name='regParam', doc='regularization parameter (>= 0).'): 20.0}, 6.636158074246821)\n",
      "({Param(parent='LinearRegression_379bee5804b7', name='regParam', doc='regularization parameter (>= 0).'): 25.0}, 6.627298251874045)\n",
      "({Param(parent='LinearRegression_379bee5804b7', name='regParam', doc='regularization parameter (>= 0).'): 30.0}, 6.635134794786982)\n"
     ]
    }
   ],
   "source": [
    "for i in zip(paramGrid_ridge, ridge_cv_model.avgMetrics):\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to achieve a turning point at `regParam=25`<br><br>\n",
    "Still, test RMSE for CV Ridge model is worse than for base Lasso. Let us evaluate on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9214690700340626"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_predictions_val = ridge_model.transform(df_val_trans)\n",
    "ridge_rmse_val = evaluator.evaluate(ridge_predictions_val)\n",
    "ridge_rmse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8701872186442867"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv_predictions_val = ridge_cv_model.transform(df_val_pipe)\n",
    "ridge_cv_rmse_val = evaluator.evaluate(ridge_cv_predictions_val)\n",
    "ridge_cv_rmse_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge model didn't outperform Lasso. Let us try the ElasticNet model, which combines both types of regularization, to see if it could outperform base Lasso model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic = LinearRegression(\n",
    "    labelCol=TARGET_VAR,\n",
    "    featuresCol=FEATURES_COL,\n",
    "    elasticNetParam=0.5,\n",
    "    regParam=REGPARAM,\n",
    "    standardization=STANDARDIZATION,\n",
    "    maxIter=MAXITER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_model = elastic.fit(X_train_mm)\n",
    "elastic_predictions = elastic_model.transform(X_test_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.405489637438942"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_rmse = evaluator.evaluate(elastic_predictions)\n",
    "elastic_rmse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try is worse than base Lasso. However, ElasticNet has two parameters to tune, so here we expect CV to bring much better improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler, elastic])\n",
    "paramGrid_elastic = ParamGridBuilder() \\\n",
    "    .addGrid(elastic.regParam, [0.1, 0.5, 1, 5, 10]) \\\n",
    "    .addGrid(elastic.elasticNetParam, np.arange(0.1, 1, 0.2)) \\\n",
    "    .build()\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid_elastic,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_cv_model = crossval.fit(X_train_pipe)\n",
    "elastic_cv_predictions = elastic_cv_model.transform(X_test_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.40894600272515"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_cv_rmse = evaluator.evaluate(elastic_cv_predictions)\n",
    "elastic_cv_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='LinearRegression_981ce767d4dc', name='regParam', doc='regularization parameter (>= 0).'): 1.0, Param(parent='LinearRegression_981ce767d4dc', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.9000000000000001} 7.96457479684676\n",
      "{Param(parent='LinearRegression_981ce767d4dc', name='regParam', doc='regularization parameter (>= 0).'): 5.0, Param(parent='LinearRegression_981ce767d4dc', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.1} 7.954137218939503\n",
      "{Param(parent='LinearRegression_981ce767d4dc', name='regParam', doc='regularization parameter (>= 0).'): 5.0, Param(parent='LinearRegression_981ce767d4dc', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.30000000000000004} 8.01195875259711\n"
     ]
    }
   ],
   "source": [
    "scores = [val for val in elastic_cv_model.avgMetrics]\n",
    "min_score = np.min(scores)\n",
    "min_score_idx = scores.index(np.min(scores))\n",
    "for i in range(min_score_idx-1, min_score_idx+2):\n",
    "    print(paramGrid_elastic[i], elastic_cv_model.avgMetrics[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV ElasticNet model is still worse than base Lasso. However, it is worth mentioning that this model didn't really overfit on training data, so it is more robust one, and perhaps will provide better results on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.880779601994567"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_predictions_val = elastic_model.transform(df_val_trans)\n",
    "elastic_rmse_val = evaluator.evaluate(elastic_predictions_val)\n",
    "elastic_rmse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8643459553038966"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_cv_predictions_val = elastic_cv_model.transform(df_val_pipe)\n",
    "elastic_cv_rmse_val = evaluator.evaluate(elastic_cv_predictions_val)\n",
    "elastic_cv_rmse_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, it is worse than base Lasso. Let us try to further improve Lasso model by trying another scaling algorithm, which in this case will be log-scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
